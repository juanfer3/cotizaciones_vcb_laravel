[["file:///home/jfvilladiego/proyectos_laravel/cotizaciones_vcb_laravel/vendor/monolog/monolog/src/Monolog/Handler/DeduplicationHandler.php",{"_uri":"file:///home/jfvilladiego/proyectos_laravel/cotizaciones_vcb_laravel/vendor/monolog/monolog/src/Monolog/Handler/DeduplicationHandler.php","_root":{"kind":4096,"name":"file:///home/jfvilladiego/proyectos_laravel/cotizaciones_vcb_laravel/vendor/monolog/monolog/src/Monolog/Handler/DeduplicationHandler.php","location":{"uriHash":673973883,"range":{"start":{"line":0,"character":0},"end":{"line":169,"character":0}}},"children":[{"kind":512,"name":"Monolog\\Handler","location":{"uriHash":673973883,"range":{"start":{"line":11,"character":0},"end":{"line":11,"character":26}}}},{"kind":1,"name":"Logger","location":{"uriHash":673973883,"range":{"start":{"line":13,"character":4},"end":{"line":13,"character":18}}},"modifiers":4096,"associated":[{"kind":1,"name":"Monolog\\Logger"}]},{"kind":1,"name":"Monolog\\Handler\\DeduplicationHandler","location":{"uriHash":673973883,"range":{"start":{"line":35,"character":0},"end":{"line":168,"character":1}}},"children":[{"kind":16,"name":"$deduplicationStore","location":{"uriHash":673973883,"range":{"start":{"line":40,"character":14},"end":{"line":40,"character":33}}},"doc":{"description":"","type":"string"},"modifiers":2,"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":16,"name":"$deduplicationLevel","location":{"uriHash":673973883,"range":{"start":{"line":45,"character":14},"end":{"line":45,"character":33}}},"doc":{"description":"","type":"int"},"modifiers":2,"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":16,"name":"$time","location":{"uriHash":673973883,"range":{"start":{"line":50,"character":14},"end":{"line":50,"character":19}}},"doc":{"description":"","type":"int"},"modifiers":2,"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":16,"name":"$gc","location":{"uriHash":673973883,"range":{"start":{"line":55,"character":12},"end":{"line":55,"character":23}}},"doc":{"description":"","type":"bool"},"value":"","modifiers":4,"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":32,"name":"__construct","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":4},"end":{"line":71,"character":5}}},"doc":{"description":"","type":""},"modifiers":1,"type":"","children":[{"kind":128,"name":"$handler","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":32},"end":{"line":64,"character":57}}},"type":"Monolog\\Handler\\HandlerInterface","doc":{"description":"Handler.","type":"Monolog\\Handler\\HandlerInterface"},"scope":"__construct"},{"kind":128,"name":"$deduplicationStore","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":59},"end":{"line":64,"character":85}}},"doc":{"description":"The file/path where the deduplication log should be kept","type":"string"},"value":"null","scope":"__construct"},{"kind":128,"name":"$deduplicationLevel","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":87},"end":{"line":64,"character":122}}},"doc":{"description":"The minimum logging level for log records to be looked at for deduplication purposes","type":"int"},"value":"Logger::ERROR","scope":"__construct"},{"kind":128,"name":"$time","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":124},"end":{"line":64,"character":134}}},"doc":{"description":"The period (in seconds) during which duplicate entries should be suppressed after a given log is sent through","type":"int"},"value":"60","scope":"__construct"},{"kind":128,"name":"$bubble","location":{"uriHash":673973883,"range":{"start":{"line":64,"character":136},"end":{"line":64,"character":150}}},"doc":{"description":"Whether the messages that are handled can bubble up the stack or not","type":"Boolean"},"value":"true","scope":"__construct"}],"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":32,"name":"flush","location":{"uriHash":673973883,"range":{"start":{"line":73,"character":4},"end":{"line":101,"character":5}}},"modifiers":1,"type":"","children":[],"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":32,"name":"isDuplicate","location":{"uriHash":673973883,"range":{"start":{"line":103,"character":4},"end":{"line":131,"character":5}}},"modifiers":4,"type":"","children":[{"kind":128,"name":"$record","location":{"uriHash":673973883,"range":{"start":{"line":103,"character":33},"end":{"line":103,"character":46}}},"type":"array","scope":"isDuplicate"}],"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":32,"name":"collectLogs","location":{"uriHash":673973883,"range":{"start":{"line":133,"character":4},"end":{"line":162,"character":5}}},"modifiers":4,"type":"","children":[],"scope":"Monolog\\Handler\\DeduplicationHandler"},{"kind":32,"name":"appendRecord","location":{"uriHash":673973883,"range":{"start":{"line":164,"character":4},"end":{"line":167,"character":5}}},"modifiers":4,"type":"","children":[{"kind":128,"name":"$record","location":{"uriHash":673973883,"range":{"start":{"line":164,"character":34},"end":{"line":164,"character":47}}},"type":"array","scope":"appendRecord"}],"scope":"Monolog\\Handler\\DeduplicationHandler"}],"associated":[{"kind":1,"name":"Monolog\\Handler\\BufferHandler"}],"doc":{"description":"Simple handler wrapper that deduplicates log records across multiple requests\n\nIt also includes the BufferHandler functionality and will buffer\nall messages until the end of the request or flush() is called.\n\nThis works by storing all log records' messages above $deduplicationLevel\nto the file specified by $deduplicationStore. When further logs come in at the end of the\nrequest (or when flush() is called), all those above $deduplicationLevel are checked\nagainst the existing stored logs. If they match and the timestamps in the stored log is\nnot older than $time seconds, the new log record is discarded. If no log record is new, the\nwhole data set is discarded.\n\nThis is mainly useful in combination with Mail handlers or things like Slack or HipChat handlers\nthat send messages to people, to avoid spamming with the same message over and over in case of\na major component failure like a database server being down which makes all requests fail in the\nsame way.","type":""},"modifiers":0}]},"_hash":673973883}]]